{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Covid Effect on AirBnB Listings & Reviews in NYC \n",
    "\n",
    "This project analysis AirBnB data in New York City Before and After Covid, trying to find and analyze the effects Covid has on the AirBnB listings and reviews with emphasis on analyzing the listing's names, descriptions and user's reviews. The data for this project has come from multiple sources listed below.\n",
    "\n",
    "This analysis is divided into 2 main parts:\n",
    "* Initial Comparison - Some basic comparison of AirBnB data between the Pre-Covid period to Covid Period\n",
    "* Further Comparison - This part is mostly based on different NLP techniques to see if there is a difference between Listing's names, descriptions and reviews between the 2 periods, and testing for different correlations between the text to other data.\n",
    "<br><br>\n",
    "\n",
    "__**Data Sources:**__\n",
    "* AirBnB Listing Information from November 2018 - https://github.com/saranggupta94/airbnb\n",
    "* AirBnB Listing Information from June 2020 - https://github.com/ioslilyng/airbnb_nyc\n",
    "* AirBnB Listing Information and Reviews from 2021 - http://insideairbnb.com/get-the-data.html\n",
    "* AirBnB Listing Information From 2019 (Kaggle) - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data\n",
    "* AirBnB Listing Information From 2020 (Kaggle) - https://www.kaggle.com/kritikseth/us-airbnb-open-data\n",
    "* NYC Covid Data - https://data.cityofnewyork.us/Health/COVID-19-Daily-Counts-of-Cases-Hospitalizations-an/rc75-m7u3\n",
    "<br>\n",
    "* This notebook can also be found in: https://colab.research.google.com/drive/1RKqgln2vMzgmftMydCYC3YEKK_KVML-E?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:55:50.310131Z",
     "start_time": "2022-02-27T17:55:50.301624Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:55:50.326145Z",
     "start_time": "2022-02-27T17:55:50.311636Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:55:50.342148Z",
     "start_time": "2022-02-27T17:55:50.327145Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "# !pip install seaborn\n",
    "# !pip install wordcloud\n",
    "# !pip install nltk\n",
    "# !pip install textblob\n",
    "# !pip install spacy\n",
    "# !pip install gensim\n",
    "# !pip install pyLDAvis\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:00:40.784138Z",
     "start_time": "2022-02-27T20:00:40.775136Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:00:48.505435Z",
     "start_time": "2022-02-27T20:00:45.530252Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from typing import List, Tuple\n",
    "import seaborn as sb\n",
    "from plotly.subplots import make_subplots\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:17.872886Z",
     "start_time": "2022-02-27T17:55:53.135779Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:18.204961Z",
     "start_time": "2022-02-27T17:56:17.873886Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:18.220965Z",
     "start_time": "2022-02-27T17:56:18.205961Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def print_bold(string):\n",
    "    display(Markdown(f'**{string}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:18.236968Z",
     "start_time": "2022-02-27T17:56:18.221965Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_listings_text(df):\n",
    "    summary = df['summary']\n",
    "    space = df['space']\n",
    "    desc = df['description']\n",
    "    ans = list()\n",
    "    for c1, c2, c3 in zip(summary, space, desc):\n",
    "        ans.append(str(c1) + \" \" + str(c2) + \" \" + str(c3))\n",
    "    new_df = df.drop(['summary', 'space'], axis=1)\n",
    "    new_df['description'] = ans\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:21.022598Z",
     "start_time": "2022-02-27T17:56:18.238970Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"data/listings-November-2018.csv\")\n",
    "df_pre = merge_listings_text(df_pre)\n",
    "df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:21.134623Z",
     "start_time": "2022-02-27T17:56:21.023598Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_kaggle_pre = pd.read_csv(\"data/AB_NYC_2019.csv\")\n",
    "df_kaggle_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:21.646738Z",
     "start_time": "2022-02-27T17:56:21.135623Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_kaggle_covid = pd.read_csv(\"data/AB_US_2020.csv\")\n",
    "df_kaggle_covid = df_kaggle_covid[df_kaggle_covid[\"city\"] == \"New York City\"]\n",
    "df_kaggle_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:23.869763Z",
     "start_time": "2022-02-27T17:56:21.647738Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_2020_lst = pd.read_csv(\"data/listings-June2020.csv\")\n",
    "df_2020_lst = merge_listings_text(df_2020_lst)\n",
    "df_2020_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:27.792650Z",
     "start_time": "2022-02-27T17:56:23.870764Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_21_march_lst = pd.read_csv(\"data/listings-march21.csv.gz\")\n",
    "df_21_june_lst = pd.read_csv(\"data/listings-june-21.csv.gz\")\n",
    "df_21_sep_lst = pd.read_csv(\"data/listings-september-21.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:12.355806Z",
     "start_time": "2022-02-27T20:01:07.243929Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"data/reviews-december-2021.csv.gz\")\n",
    "df_reviews[\"date\"] = df_reviews[\"date\"].astype('datetime64')\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:12.418820Z",
     "start_time": "2022-02-27T20:01:12.371811Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pre_reviews = df_reviews[(df_reviews[\"date\"] < \"2020-02-29\") & (df_reviews[\"date\"] >= \"2018-11-15\")]\n",
    "df_pre_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:12.466831Z",
     "start_time": "2022-02-27T20:01:12.435825Z"
    }
   },
   "outputs": [],
   "source": [
    "df_covid_reviews = df_reviews[df_reviews[\"date\"] >= \"2020-02-29\"]\n",
    "df_covid_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:33.221498Z",
     "start_time": "2022-02-27T17:56:33.190491Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ny_covid_data = pd.read_csv(\"data/NYC-covid-data-day-by-day.csv\")\n",
    "df_ny_covid_data['DATE_OF_INTEREST'] = pd.to_datetime(df_ny_covid_data['DATE_OF_INTEREST'])\n",
    "df_ny_covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:33.237501Z",
     "start_time": "2022-02-27T17:56:33.222498Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RENDERER = 'notebook'   # Jupyter notebook\n",
    "# RENDERER = 'jupyterlab'   # Data spell\n",
    "# RENDERER = 'colab'      # Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initial Comparison\n",
    "\n",
    "Start with initial data exploration and differences between Pre-Covid and Covid Periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## General Covid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:33.253505Z",
     "start_time": "2022-02-27T17:56:33.238502Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def covid_moving_avg(orig_df, title):\n",
    "    df = orig_df.groupby('DATE_OF_INTEREST').sum().reset_index().loc[:, ['DATE_OF_INTEREST','CASE_COUNT']]\n",
    "    df[\"avg\"] = df['CASE_COUNT'].rolling(7).sum()\n",
    "    return px.line(df, x='DATE_OF_INTEREST', y=\"avg\", title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:33.773629Z",
     "start_time": "2022-02-27T17:56:33.254505Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "covid_moving_avg(df_ny_covid_data, \"7-Day Moving Average Covid New Cases in NYC\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that in NYC there were 3 waves. The first from mid March 2020 to July 2020 The second form November 2020 to June 2021 and from December 2021 to February 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Prices Comparison\n",
    "\n",
    "Checking for differences in amount of listings and prices due to Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:33.789636Z",
     "start_time": "2022-02-27T17:56:33.774629Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_kaggle_pre_neighborhood = df_kaggle_pre[df_kaggle_pre[\"price\"] != 0].groupby(\"neighbourhood_group\")\n",
    "df_kaggle_covid_neighborhood = df_kaggle_covid[df_kaggle_covid[\"price\"] != 0].groupby(\"neighbourhood_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.091701Z",
     "start_time": "2022-02-27T17:56:33.790634Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_n_count = df_kaggle_pre_neighborhood.count()['id'].to_frame().reset_index().rename(columns={\"id\": \"2019\"}).astype({\"neighbourhood_group\": 'string'})\n",
    "covid_n_count = df_kaggle_covid_neighborhood.count()['id'].to_frame().reset_index().rename(columns={\"id\": \"2020\"}).astype({\"neighbourhood_group\": 'string'})\n",
    "pre_n_max = df_kaggle_pre_neighborhood.max()['price'].to_frame().reset_index().rename(columns={\"price\": \"2019\"}).astype({\"neighbourhood_group\": 'string'})\n",
    "covid_n_max = df_kaggle_covid_neighborhood.max()['price'].to_frame().reset_index().rename(columns={\"price\": \"2020\"}).astype({\"neighbourhood_group\": 'string'})\n",
    "pre_n_min = df_kaggle_pre_neighborhood.min()['price'].to_frame().reset_index().rename(columns={\"price\": \"2019\"}).astype({\"neighbourhood_group\": 'string'})\n",
    "covid_n_min = df_kaggle_covid_neighborhood.min()['price'].to_frame().reset_index().rename(columns={\"price\": \"2020\"}).astype({\"neighbourhood_group\": 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.218236Z",
     "start_time": "2022-02-27T17:56:34.092701Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def comparison_bar_plot(dfs: Tuple, names, x_name = \"neighbourhood_group\", y_names = (\"2019\", \"2020\"), title = None, axes_titles = {\"x\": None, \"y\": None},\n",
    "                        print_diff=False):\n",
    "    xs = [df[x_name].to_list() for df in dfs]\n",
    "    ys = [df[y_name].to_list() for df, y_name in zip(dfs, y_names)]\n",
    "    max_y = max([max(y) for y in ys])\n",
    "    fig = go.Figure(layout=dict(\n",
    "        title=title,\n",
    "        yaxis={\"title\": axes_titles[\"y\"], \"range\": [0 - max_y*0.1 if print_diff else 0, max_y * 1.2]},\n",
    "        xaxis={\"title\": axes_titles[\"x\"]}\n",
    "    ))\n",
    "    for curr_x, curr_y, curr_name in zip(xs, ys, names):\n",
    "        fig.add_trace(go.Bar(x=curr_x, y=curr_y, text=curr_y, textposition=\"outside\", name=curr_name))\n",
    "    if print_diff:\n",
    "        for curr, v1, v2 in zip(xs[0], ys[0], ys[1]):\n",
    "            diff = abs(v1-v2)\n",
    "            fig.add_annotation(x=curr, text=f\"Difference: {diff}\", showarrow=False, yref=\"paper\", yanchor=\"bottom\", y=0, font={\"color\": \"red\"})\n",
    "    return fig\n",
    "\n",
    "\n",
    "comparison_bar_plot((pre_n_count, covid_n_count), names=[\"Pre-Covid\", \"During Covid\"], title=\"Number of Listings Pre and During Covid\",\n",
    "                    axes_titles = {\"x\": \"Neighbourhood Group\", \"y\": \"No. of Listings\"}, print_diff=True).show(renderer=RENDERER)\n",
    "\n",
    "comparison_bar_plot((pre_n_max, covid_n_max), y_names = (\"2019\", \"2020\"), names=[\"Pre-Covid\", \"During Covid\"],\n",
    "                    title=\"Maximum Listing Price\", axes_titles = {\"x\": \"Neighbourhood Group\", \"y\": \"Max Listing Price\"}, print_diff=True).show(renderer=RENDERER)\n",
    "\n",
    "comparison_bar_plot((pre_n_min, covid_n_min), y_names = (\"2019\", \"2020\"), names=[\"Pre-Covid\", \"During Covid\"],\n",
    "                    title=\"Minimum Listing Price\", axes_titles = {\"x\": \"Neighbourhood Group\", \"y\": \"Min Listing Price\"}, print_diff=True).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.489085Z",
     "start_time": "2022-02-27T17:56:34.220236Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_box_price(pre, during):\n",
    "    z1 = pre.loc[:,[\"neighbourhood_group\", \"price\", \"latitude\", \"longitude\"]]\n",
    "    z1[\"year\"] = \"Pre-Covid\"\n",
    "    z2 = during.loc[:,[\"neighbourhood_group\", \"price\", \"latitude\", \"longitude\"]]\n",
    "    z2[\"year\"] = \"Covid\"\n",
    "    data = pd.concat((z1,z2))\n",
    "    fig, ax = plt.subplots(figsize=(20, 9))\n",
    "    order = data[\"neighbourhood_group\"].unique().tolist()\n",
    "    order.sort()\n",
    "    ax = sb.boxplot(x=\"neighbourhood_group\", y=\"price\", data=data, showfliers=False, hue=\"year\", ax=ax,order=order)\n",
    "    ax.set(xlabel = 'Neighbourhood Group', ylabel = 'Price')\n",
    "    plt.legend(title='Time Period')\n",
    "    return fig\n",
    "\n",
    "draw_box_price(df_kaggle_pre, df_kaggle_covid).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__**Prices Conclusions**__\n",
    "\n",
    "**Number of listings in Brooklyn and Manhattan have decreased due to Covid and increased slightly in other regions.\n",
    "\n",
    "We can see that the amount of listings between the pre-covid time to 2020 (Start and middle of Covid) The amount of listings has dropped in most NYC regions.\n",
    "The maximum asking price in Bronx and Staten Island have changed significantly while in other places it stayed the same. Surprisingly, the minimum asking price have increased in these 2 regions(Bronx and Staten Island) and stayed almost the same in other places.\n",
    "\n",
    "In most neighborhoods the mean prices have stayed the same except for Manhattan where it has dropped significantly. Also, prices range have stayed mostly the same except for the Bronx.**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Room Types\n",
    "\n",
    "Checking if there was any difference in room type's offered in AirBnB due to Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.614114Z",
     "start_time": "2022-02-27T17:56:34.491085Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_rooms_bar(pre, during):\n",
    "    z1 = pre.groupby([\"neighbourhood_group\",\"room_type\"]).count()[\"id\"].reset_index().rename(columns={\"id\": \"2019\"})\n",
    "    z2 = during.groupby([\"neighbourhood_group\",\"room_type\"]).count()[\"id\"].reset_index().rename(columns={\"id\": \"2020\"})\n",
    "    data = pd.merge(z1,z2)\n",
    "    room_types = data[\"room_type\"].unique().tolist()\n",
    "    fig = make_subplots(1,3, column_titles=room_types)\n",
    "    fig.update_layout(title=\"Amount of Listing per Room Type\")\n",
    "    # neighborhoods = data[\"neighbourhood_group\"].unique().tolist()\n",
    "    for idx, rt in enumerate(room_types):\n",
    "        curr = data[data[\"room_type\"]==rt]\n",
    "        fig.add_trace(go.Bar(x = curr[\"neighbourhood_group\"].tolist(), y=curr[\"2019\"].tolist(), name=f\"2019-{rt}\", marker_color=\"blue\"), row=1, col=idx+1)\n",
    "        fig.add_trace(go.Bar(x = curr[\"neighbourhood_group\"].tolist(), y=curr[\"2020\"].tolist(), name=f\"2020-{rt}\", marker_color=\"red\"), row=1, col=idx+1)\n",
    "    return fig\n",
    "\n",
    "draw_rooms_bar(df_kaggle_pre, df_kaggle_covid).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**We can see that there was a decrease in the amount of shared rooms across all neighborhoods, to be expected during a pandemic.**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Average Reviews in a Month\n",
    "\n",
    "From the data we can't really know about the amount of reservations made, but the amount of reviews can be a close enough proxy for this.\n",
    "\n",
    "Checking the changes in average number of reviews over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.723138Z",
     "start_time": "2022-02-27T17:56:34.616114Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_avg_reviews_per_month(pre, covid):\n",
    "    z1 = pre.groupby(\"neighbourhood_group\").mean()[\"reviews_per_month\"].reset_index().rename(columns={\"reviews_per_month\": \"2019\"})\n",
    "    z2 = covid.groupby(\"neighbourhood_group\").mean()[\"reviews_per_month\"].reset_index().rename(columns={\"reviews_per_month\": \"2020\"})\n",
    "    data = pd.merge(z1,z2)\n",
    "    return px.bar(data, x=\"neighbourhood_group\", y=[\"2019\",\"2020\"], barmode=\"group\", title=\"Average Number of Reviews in Each Neigborhood\")\n",
    "\n",
    "draw_avg_reviews_per_month(df_kaggle_pre, df_kaggle_covid).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**The average number of reviews has lowered in all the different neighborhoods, as expected when the number of bookings decreased due to Covid-19.**\n",
    "<br><br><br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.738141Z",
     "start_time": "2022-02-27T17:56:34.727139Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_moving_avg(orig_df, col_name, title):\n",
    "    df = orig_df.groupby('date').count().reset_index().loc[:, ['date', col_name]]\n",
    "    df['avg'] = df[col_name].rolling(7).sum()\n",
    "    return px.line(df, x='date', y=col_name, title=title,line_shape='spline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:34.929184Z",
     "start_time": "2022-02-27T17:56:34.739141Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_moving_avg(df_pre_reviews, 'comments', \"Pre-Covid 7 Day Moving Average Reviews Amount\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:35.087220Z",
     "start_time": "2022-02-27T17:56:34.930185Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_moving_avg(df_covid_reviews, 'comments', \"Covid 7 Day Moving Average Reviews Amount\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From the amounts of reviews we can see that during almost 2 years of Covid there were less reviews in AirBnB compared to a pre-covid period with same length.\n",
    "We can also see that the first wave in NYC caused a big drop in amount of reviews, probably due to a drop in the amount bookings. Other waves didn't affect the amount of reviews that kept growing steadily till the end of the data (except for last 2 weeks) This can be because of the third wave or because the data ends.\n",
    "<br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Comparison\n",
    "\n",
    "This part included more complex comparison mostly based on NLP techniques on the Listing's names, descriptions and reviews.\n",
    "\n",
    "This part is separated according to the type of parameter used for comparison the parameters are: Listing's Name, Listing's Description, User Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Functionality\n",
    "\n",
    "Below is a list of words that are related to Covid that I'll refer to as Covid Related Words. I'll use these words for checking data that is connected to Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:46.367415Z",
     "start_time": "2022-02-27T20:01:46.364415Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "COVID_WORDS = list({'covid', 'influenza', 'sanitized', \"cdc\", \"corona\", 'coronavirus', 'virus', 'healthcare', 'disinfection', 'disinfected', 'lysol', 'disinfect',\n",
    "               'sanitizer', 'sanitized', 'sanitize', 'disease', 'prevention', 'quarantine', 'distancing', 'pandemic', 'germ', 'germs', 'germ-fre', 'germ-free',\n",
    "               'covid-19', 'covid19', 'co-vid', 'corona', 'virus', 'viruses', 'disease', 'bacterial', 'bacteria', 'antibacterial', 'anti-bacterial', 'vaccine',\n",
    "               'vaccinated', 'vaccinations', 'vaccines', 'epidemic', 'pandemic', 'outbreak', 'isolation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:46.892201Z",
     "start_time": "2022-02-27T20:01:46.866672Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "TO_REMOVE_IRRELEVANT = None\n",
    "\n",
    "def strip_punc_digit(word):\n",
    "    return re.sub(r'(<.+>)|[\\d]|[^\\w\\s]', \"\", word)\n",
    "\n",
    "def exclude_word(word):\n",
    "    global TO_REMOVE_IRRELEVANT\n",
    "    if TO_REMOVE_IRRELEVANT is None:\n",
    "        irrelevant_worlds = {\"U\", \"Jr\", \"W\", \"E\", \"S\", \"N\", \"Nr\", \"East\", \"West\", \"South\", \"North\", \"Est\", \"Sou\",\n",
    "                             \"street\", \"boulevard\", \"br\", \"st\", \"th\", \"j\", \"Ny\", \"nyc\", \"new york\"}\n",
    "        to_remove = irrelevant_worlds.union(STOPWORDS)\n",
    "        to_remove = to_remove.union(nltk_stopwords.words(\"spanish\"))\n",
    "        to_remove = to_remove.union(nltk_stopwords.words(\"french\"))\n",
    "        to_remove = {word.lower() for word in to_remove}\n",
    "        TO_REMOVE_IRRELEVANT = to_remove\n",
    "\n",
    "    return word.lower() in TO_REMOVE_IRRELEVANT\n",
    "\n",
    "\n",
    "def create_word_counts(sentences_lst: List[str], min_count: int):\n",
    "    all_words = [strip_punc_digit(word)  for name in sentences_lst for word in str(name).split(\" \")]\n",
    "    clean_words = [word.lower().capitalize() for word in all_words if not exclude_word(word) and word != \"\"]\n",
    "    counts = Counter(clean_words)\n",
    "    filtered_counts = {k: v for k,v in dict(counts).items() if v > min_count}\n",
    "    return filtered_counts\n",
    "\n",
    "\n",
    "def create_word_cloud(sentences_lst: List[str], min_count: int, **kwargs):\n",
    "    filtered_counts = create_word_counts(sentences_lst, min_count)\n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                          background_color ='white',\n",
    "                          stopwords = set(STOPWORDS),\n",
    "                          min_font_size = 10,\n",
    "                          **kwargs)\n",
    "    return wordcloud.generate_from_frequencies(filtered_counts)\n",
    "\n",
    "\n",
    "def new_words_after_covid(pre: List[List[str]], covid: List[List[str]], title: str, words_to_show=50):\n",
    "    pre_words = set()\n",
    "    for sentences_lst in pre:\n",
    "        pre_words.update({strip_punc_digit(word.lower()).encode(\"ascii\", \"ignore\").decode(\"utf-8\") for sentence in sentences_lst\n",
    "                          for word in str(sentence).split(\" \")  if not exclude_word(word)})\n",
    "    all_covid_words = list()\n",
    "    for sentences_lst in covid:\n",
    "        all_covid_words += [strip_punc_digit(word.lower()).encode(\"ascii\", \"ignore\").decode(\"utf-8\") for sentence in sentences_lst\n",
    "                            for word in str(sentence).split(\" \") if not exclude_word(word)]\n",
    "    new_words = {word for word in set(all_covid_words) if word not in pre_words}\n",
    "    counts = Counter(all_covid_words)\n",
    "    new_words_counts = {word: counts.get(word) for word in new_words}\n",
    "    new_words_counts = {k:v for k, v in sorted(new_words_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "    fig = go.Figure(layout=dict(title=title))\n",
    "    fig.add_trace(go.Bar(x=list(new_words_counts.keys())[:words_to_show], y=list(new_words_counts.values())[:words_to_show]))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def words_change(pre: List[List[str]], covid: List[List[str]], title, sub_titles,\n",
    "                 words_to_show = 50, min_count = 50):\n",
    "    pre_conc = [sentence for sentences_lst in pre for sentence in sentences_lst]\n",
    "    covid_conc = [sentence for sentences_lst in covid for sentence in sentences_lst]\n",
    "    pre_count = create_word_counts(pre_conc, min_count)\n",
    "    covid_count = create_word_counts(covid_conc, min_count)\n",
    "    diffs = {k: (v - covid_count.get(k,0)) for k, v in pre_count.items()}\n",
    "    diffs = {k: v for k, v in sorted(diffs.items(), key=lambda item: item[1], reverse=True)}\n",
    "    neg_diffs = dict()\n",
    "    for word, count in reversed(diffs.items()):\n",
    "        if count < 0:\n",
    "            neg_diffs[word] = abs(count)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    fig = make_subplots(2,1, vertical_spacing=0.4, subplot_titles=sub_titles)\n",
    "    fig.add_trace(go.Bar(x=list(diffs.keys())[:words_to_show],y=list(diffs.values())[:words_to_show], name=\"More occurrences Pre-Covid\"), row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=list(neg_diffs.keys())[:words_to_show],y=list(neg_diffs.values())[:words_to_show], name=\"Less occurrences Pre-Covid\"), row=2, col=1)\n",
    "    fig.update_layout(title=title, height=600, showlegend=False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:48.733219Z",
     "start_time": "2022-02-27T20:01:48.723216Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentiment_analysis(data_lst: List[List[str]]):\n",
    "    ans_info = {\"polarity\": list(), \"subjectivity\": list()}\n",
    "    for sentences_lst in data_lst:\n",
    "        for sentence in sentences_lst:\n",
    "            ans = TextBlob(str(sentence))\n",
    "            ans_info[\"polarity\"].append(ans.sentiment[0])\n",
    "            ans_info[\"subjectivity\"].append(ans.sentiment[1])\n",
    "    return ans_info\n",
    "\n",
    "\n",
    "def sentiment_analysis_diff(pre: List[List[str]], covid: List[List[str]], title):\n",
    "    pre_info = get_sentiment_analysis(pre)\n",
    "    covid_info = get_sentiment_analysis(covid)\n",
    "\n",
    "    fig = go.Figure(layout=dict(title=title))\n",
    "    fig.add_trace(go.Box(y=pre_info['polarity'], name=\"Pre-Covid Polarity\"))\n",
    "    fig.add_trace(go.Box(y=covid_info['polarity'], name=\"Covid Polarity\"))\n",
    "    fig.add_trace(go.Box(y=pre_info['subjectivity'], name=\"Pre-Covid Subjectivity\"))\n",
    "    fig.add_trace(go.Box(y=covid_info['subjectivity'], name=\"Covid Subjectivity\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:49.432235Z",
     "start_time": "2022-02-27T20:01:49.427234Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_words_in_df(df,  words: List[str], text_col: str):\n",
    "    ps = PorterStemmer()\n",
    "    words = [ps.stem(word).lower() for word in words]\n",
    "\n",
    "    def words_counter(sentence):\n",
    "        if not isinstance(sentence, str):\n",
    "            return 0, 0, 0\n",
    "        count = 0\n",
    "        split_sentence = sentence.split(\" \")\n",
    "        split_sentence = [ps.stem(word).lower() if isinstance(word, str) else word for word in split_sentence]\n",
    "        for word in words:\n",
    "            count += split_sentence.count(word.lower())\n",
    "        return count, len(split_sentence), count/len(split_sentence)\n",
    "\n",
    "    count_data = df[text_col].apply(words_counter)\n",
    "    df['counts'] = [count[0] for count in count_data]\n",
    "    df['total'] = [count[1] for count in count_data]\n",
    "    df['ratio'] = [count[2] for count in count_data]\n",
    "    return df\n",
    "\n",
    "# get_price_words_corr_df(df_kaggle_pre[[\"id\",\"price\"]][:500], df_pre_reviews[['listing_id','comments']][:500], left_on='id', right_on='listing_id', words=COVID_WORDS, text_col='comments').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:50.638826Z",
     "start_time": "2022-02-27T20:01:50.627321Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_text_diff(df_pre, df_covid, left_on, right_on, diff_col, relevant_words: List[str]):\n",
    "    ps = PorterStemmer()\n",
    "    relevant_words = [ps.stem(word).lower() for word in relevant_words] if relevant_words is not None else None\n",
    "\n",
    "    def find_diff(data):\n",
    "        ans = list()\n",
    "        not_related_ans = list()\n",
    "        old = data[0]\n",
    "        new = data[1]\n",
    "        if not isinstance(old, str) or not isinstance(new, str) or old == new:\n",
    "            return ans, not_related_ans\n",
    "        old = [ps.stem(word).lower() for word in old.split(\" \")]\n",
    "        new = [ps.stem(word).lower() for word in new.split(\" \")]\n",
    "        for word in new:\n",
    "            word = strip_punc_digit(word)\n",
    "            if word not in old:\n",
    "                if (relevant_words is not None and word in relevant_words) or (relevant_words is None):\n",
    "                    ans.append(word)\n",
    "                else:\n",
    "                    not_related_ans.append(word)\n",
    "        return ans, not_related_ans\n",
    "\n",
    "    df = df_pre if df_covid is None else pd.merge(df_pre, df_covid, left_on=left_on, right_on=right_on, suffixes=(\"_old\",\"_new\"))\n",
    "    olds = df[f'{diff_col}_old']\n",
    "    news = df[f'{diff_col}_new']\n",
    "    diffs = list(map(find_diff, zip(olds, news)))\n",
    "    return diffs, df\n",
    "\n",
    "def calc_diff_amounts(df_pre, df_covid, left_on, right_on, diff_cols: List[str], relevant_words: List[str]):\n",
    "    ans = list()\n",
    "    total_changes = list()\n",
    "    df = pd.merge(df_pre, df_covid, left_on=left_on, right_on=right_on, suffixes=(\"_old\",\"_new\"))\n",
    "    for curr_col in  diff_cols:\n",
    "        diffs, df = find_text_diff(df, None, left_on, right_on, curr_col, relevant_words)\n",
    "        diff_count = sum([1 if len(curr[0]) != 0 else 0 for curr in diffs])\n",
    "        word_counts = {word: sum([curr[0].count(word) for curr in diffs]) for word in relevant_words}\n",
    "        word_counts = {word: count for word, count in word_counts.items() if count > 0}\n",
    "        total_changes.append(sum([1 if len(curr[0]) != 0  or len(curr[1]) != 0 else 0 for curr in diffs]))\n",
    "        ans.append((word_counts, diff_count, len(df)))\n",
    "\n",
    "    return ans, total_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:01:51.951728Z",
     "start_time": "2022-02-27T20:01:51.945727Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_and_flatten_corpus(data: List[List[str]]):\n",
    "    corpus = [sentece for part in data for sentece in part]\n",
    "    lem_corpus = list()\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sentence in corpus:\n",
    "        if sentence == \"\" or not isinstance(sentence, str):\n",
    "            continue\n",
    "        doc = nlp(sentence)\n",
    "        lem_words = [token.lemma_ for token in doc]\n",
    "        new_sentence = \" \".join(lem_words).encode(\"ascii\", \"ignore\").decode(\"utf-8\").strip()\n",
    "        if len(new_sentence) == 0:\n",
    "            continue\n",
    "        lem_corpus.append(new_sentence)\n",
    "    return lem_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Names\n",
    "\n",
    "Exploring data about Listing's names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Words in Names Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:35.198245Z",
     "start_time": "2022-02-27T17:56:35.183242Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_name_word_cloud(df, title, min_count = 500):\n",
    "    names = df[\"name\"].tolist()\n",
    "    plt.figure(figsize = (15, 15), facecolor = None)\n",
    "    plt.title(title)\n",
    "    plt.imshow(create_word_cloud(names, min_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Word Cloud of Words in Names Pre-Covid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:36.211650Z",
     "start_time": "2022-02-27T17:56:35.199245Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_name_word_cloud(df_pre, \"Words in Listings Names Before Covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Word Cloud of Words in Names Pre-Covid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:37.213877Z",
     "start_time": "2022-02-27T17:56:36.212650Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_name_word_cloud(df_2020_lst,\"Words in Listings Names After Covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### New Words Added to Names During Covid\n",
    "\n",
    "Checking for new words in the listing's names that weren't used before Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:39.165852Z",
     "start_time": "2022-02-27T17:56:37.214877Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_words_after_covid([df_pre[\"name\"].tolist(), df_kaggle_pre[\"name\"].tolist()],\n",
    "                      [df_2020_lst[\"name\"].tolist(), df_21_march_lst[\"name\"].tolist(), df_21_june_lst[\"name\"].tolist()],\n",
    "                      \"Top New Words in Listing's Names During Covid\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From this graph we can see that 3 main groups of new words were added to the listings names:\n",
    "* Companies - companies that started listing in AirBNB during Covid, or maybe even new companies created during Covid, like: Alohause, Staypineapple, Incentra and more.\n",
    "* Words directly related to Covid - like: CDC, sanitized, disinfected and more.\n",
    "* Words Relevant to the Life Covid Created - like: WFH, Peloton (home exercise equipment company), cubicle and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Word Occurrences Changes Pre & During Covid\n",
    "\n",
    "Trying to see biggest change in words occurrences before and during Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:56:40.040050Z",
     "start_time": "2022-02-27T17:56:39.166852Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_change([df_pre[\"name\"].tolist()], [df_2020_lst[\"name\"].tolist()],\n",
    "             \"Top Words Occurrences Difference Pre-covid than During Covid\",\n",
    "             [\"Words Occurrences Difference Higher Pre-Covid \", \"Words Occurences Difference Lower During Covid\"]).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**We see a decrease in the usage of words that are directly connected to Covid restrictions like: Gym (less relevant due to restriction), Park (more relevant when other places are closed), JFK & LGA (Airports, less relevant when there are less flights).**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sentiment Change in Listing's Names Pre & During Covid\n",
    "\n",
    "Trying to see if there is any difference in Sentiment (Subjectivity & Polarity) in Listing's names due to Covid.\n",
    "\n",
    "Sentiment Analysis in this project is done using TextBlob library (https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:57:05.769911Z",
     "start_time": "2022-02-27T17:56:40.041052Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis_diff([df_pre[\"name\"].tolist(), df_kaggle_pre[\"name\"].tolist()],\n",
    "                        [df_2020_lst[\"name\"].tolist(), df_21_march_lst[\"name\"].tolist(), df_21_june_lst[\"name\"].tolist(), df_21_sep_lst[\"name\"].tolist()],\n",
    "                        \"Subjectivity and Polarity of Listings Names Before and During Covid\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**There is almost no difference in names polarity and subjectivity from due to Covid**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Descriptions\n",
    "\n",
    "Exploring data about Listing's Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Words in Descriptions Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:57:05.785916Z",
     "start_time": "2022-02-27T17:57:05.770912Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_description_word_cloud(df, title, min_count = 850):\n",
    "    names = df[\"description\"].tolist()\n",
    "    plt.figure(figsize = (15, 15), facecolor = None)\n",
    "    plt.title(title)\n",
    "    plt.imshow(create_word_cloud(names, min_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Word Cloud of Words in Descriptions Pre-Covid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:57:21.147687Z",
     "start_time": "2022-02-27T17:57:05.786916Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_description_word_cloud(df_pre, \"Words in Listings Descriptions Before Covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T17:17:22.670153Z",
     "start_time": "2022-02-26T17:17:22.653135Z"
    },
    "hidden": true
   },
   "source": [
    "**Word Cloud of Words in Description During Covid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:57:36.036820Z",
     "start_time": "2022-02-27T17:57:21.148687Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_description_word_cloud(df_2020_lst, \"Words in Listings Descriptions After Covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### New Words Added to Descriptions During Covid\n",
    "\n",
    "Checking for new words in the listing's descriptions that weren't used before Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:57:59.251693Z",
     "start_time": "2022-02-27T17:57:36.037821Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_words_after_covid([df_pre[\"description\"].tolist()],\n",
    "                      [df_2020_lst[\"description\"].tolist()],\n",
    "                      \"Top New Words in Listing's Description During Covid\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**As in the names we see the names of different companies that are new and words relevant to covid (CDC, Covid, virus, etc.).\n",
    "There is also new words regarding Covid life, like: Chromecast, Liveready (Sound systems seller).**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Word Occurrences Changes Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:58:27.373563Z",
     "start_time": "2022-02-27T17:57:59.252694Z"
    },
    "hidden": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_change([df_pre[\"description\"].tolist()], [df_2020_lst[\"description\"].tolist()],\n",
    "             \"Top Words Occurrences Difference Pre-covid than During Covid in Descriptions\",\n",
    "             [\"Words Occurrences Difference Higher Pre-Covid \", \"Words Occurences Difference Lower During Covid\"]).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sentiment Change in Listing's Descriptions Pre & During Covid\n",
    "\n",
    "Trying to see if there is any difference in Sentiment (Subjectivity & Polarity) in Listing's descriptions due to Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:00.930332Z",
     "start_time": "2022-02-27T17:58:27.375564Z"
    },
    "hidden": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis_diff([df_pre[\"description\"].tolist()],\n",
    "                        [df_2020_lst[\"description\"].tolist(), df_21_march_lst[\"description\"].tolist(),\n",
    "                         df_21_june_lst[\"description\"].tolist(), df_21_sep_lst[\"description\"].tolist()],\n",
    "                        \"Subjectivity and Polarity of Listings Names Before and During Covid\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**As with the names there is almost no difference in polarity and subjectivity in the descriptions**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Name & Descriptions\n",
    "\n",
    "Exploring difference in both names and descriptions due to Covid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Covid Words Changes in Names & Descriptions\n",
    "\n",
    "Exploring how many names and listings have changed to include Covid Related Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:53.633588Z",
     "start_time": "2022-02-27T18:01:00.932333Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def names_descriptions_covid_words():\n",
    "    diffs_name, name_changes = calc_diff_amounts(df_kaggle_pre, df_kaggle_covid, left_on='id', right_on='id', diff_cols=['name'], relevant_words=COVID_WORDS)\n",
    "    diffs_name = diffs_name[0]\n",
    "    name_changes = name_changes[0]\n",
    "    diffs_description, desc_changes = calc_diff_amounts(df_pre, df_2020_lst, left_on='id', right_on='id', diff_cols=['description'], relevant_words=COVID_WORDS)\n",
    "    diffs_description = diffs_description[0]\n",
    "    desc_changes = desc_changes[0]\n",
    "    print('n\\n')\n",
    "    print_bold(f\"Listing's names found before and after covid: {diffs_name[2]}. Listing's names changed: {name_changes}.\"\n",
    "          f\" Listing's names change with Covid words: {diffs_name[1]}\")\n",
    "    print('n\\n')\n",
    "    print_bold(f\"Listing' descriptions found before and after covid: {diffs_description[2]}. Listing's descriptions changed: {desc_changes}.\"\n",
    "          f\" Listing's descriptions change with Covid words: {diffs_description[1]}\")\n",
    "    print('n\\n\\n')\n",
    "    fig = go.Figure(layout=dict(title=\"Amount of Covid Related Words Changes From Pre-covid Listing's Names & Descriptions\", yaxis_title=\"Covid Related Word\", xaxis_title='Amount of Changes Including the Word'))\n",
    "    fig.add_trace(go.Bar(x=list(diffs_name[0].keys()), y=list(diffs_name[0].values()), name=\"Name Changes\"))\n",
    "    fig.add_trace(go.Bar(x=list(diffs_description[0].keys()), y=list(diffs_description[0].values()), name=\"Description Changes\"))\n",
    "    fig.update_yaxes()\n",
    "    fig.show(renderer=RENDERER)\n",
    "\n",
    "names_descriptions_covid_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Surprisingly only a small portion of the listings before and after covid have changed their name and description to include Covid related words, although a significant amount of names and descriptions were changed.**\n",
    "<br><br><br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check for Price Changes in Listings with Names & Descriptions Changes\n",
    "\n",
    "Trying to find if there is any difference in price changes in listings that have also changed their description or name during covid and listings that haven't changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:53.649316Z",
     "start_time": "2022-02-27T18:01:53.634590Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_split_by_changes(df_pre, df_covid, relevant_words):\n",
    "    df = pd.merge(df_pre, df_covid, on='id',suffixes=(\"_old\",\"_new\"))\n",
    "    ps = PorterStemmer()\n",
    "    relevant_words = [ps.stem(word).lower() for word in relevant_words] if relevant_words is not None else None\n",
    "\n",
    "    def helper(data):\n",
    "        old_name = data[0]\n",
    "        new_name = data[1]\n",
    "        old_desc = data[2]\n",
    "        new_desc = data[3]\n",
    "        for word in relevant_words:\n",
    "            if (word in str(old_name) and word not in str(new_name)) or (word in old_desc and str(word) not in str(new_desc)):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    changed_cond = (df['name_old'] == df['name_new']) & (df['description_old'] == df['description_new'])\n",
    "    df_same = df[changed_cond]\n",
    "    df_diff = df[~changed_cond]\n",
    "    old_name = df_diff['name_old']\n",
    "    new_name = df_diff['name_new']\n",
    "    old_description = df_diff['description_old']\n",
    "    new_description = df_diff['description_new']\n",
    "    covid_change = list(map(helper,zip(old_name, new_name, old_description, new_description)))\n",
    "    covid_change_df = df_diff[covid_change]\n",
    "    changed_df = df_diff[[not x for x in covid_change]]\n",
    "\n",
    "    return df_same, covid_change_df, changed_df\n",
    "\n",
    "\n",
    "def get_price_diffs(df):\n",
    "    price_to_float = lambda price: float(re.sub(\"[,\\\\$]\",\"\", price))\n",
    "    old = df['price_old'].apply(price_to_float)\n",
    "    new = df['price_new'].apply(price_to_float)\n",
    "    return new - old\n",
    "\n",
    "\n",
    "def create_price_diffs_fig(same_df, covid_change_df, non_covid_change_df, title):\n",
    "    same_changes = get_price_diffs(same_df)\n",
    "    covid_changes = get_price_diffs(covid_change_df)\n",
    "    non_covid_changes = get_price_diffs(non_covid_change_df)\n",
    "    changes_arr = [same_changes, covid_changes, non_covid_changes]\n",
    "    names = [name for name, x in zip([\"No Change\", 'Covid Word Change', 'Non Covid Word Change'], changes_arr) if len(x) > 0]\n",
    "    data = [np.mean(x) for x in changes_arr if len(x) > 0]\n",
    "    fig = go.Figure(layout=dict(title=title, xaxis_title='Type of Change', yaxis_title='Mean Price Change'))\n",
    "    fig.add_trace(go.Bar(x=names, y=data))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:54.173010Z",
     "start_time": "2022-02-27T18:01:53.650316Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_price_diffs_fig(*merge_split_by_changes(df_pre[['id', 'name', 'description','price']], df_2020_lst[['id', 'name', 'description','price']], COVID_WORDS),\n",
    "                       \"Mean Prices Change From Pre-Covid to Start of Covid (June-2020)\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**We can see that listings that didn't changed their name or description during covid have a slightly increased price, while other listings that changed their name or description have lowered their price. Listings that changed their name or description with Covid related words have a log bigger change than changed that don't include Covid words.**\n",
    "<br><br><br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:54.787148Z",
     "start_time": "2022-02-27T18:01:54.174011Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_price_diffs_fig(*merge_split_by_changes(df_pre[['id', 'name', 'description','price']], df_21_sep_lst[['id', 'name', 'description','price']], COVID_WORDS),\n",
    "                       \"Mean Prices Change From Pre-Covid to Latest Time (September 2021) (Covid is around for a while)\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**The data doesn't have a listing that didn't changed its price from Pre covid to September 2021 (to be expected with inflation).\n",
    "Interestingly we can see that all listings have increased their price and listings that have Covid related words have increased their price more than listings that changed without using Covid words.**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Correlation Between Covid Words and Price\n",
    "\n",
    "Checking for correlation between Covid words occurrences in listings names and descriptions to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:01:54.803162Z",
     "start_time": "2022-02-27T18:01:54.788148Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def corr_covid_words_price_names_desc():\n",
    "    fix_price = lambda pr: float(re.sub(\"[,\\\\$]\",\"\", pr))\n",
    "    df = count_words_in_df(df_2020_lst, COVID_WORDS, 'name')[['counts','total','ratio','price']]\n",
    "    df['price'] = df['price'].apply(fix_price)\n",
    "    name_df = df.corr().loc[['counts','total', 'ratio'], 'price']\n",
    "    name_df = name_df.rename({\"counts\": 'Covid Words Used in Name', 'total': 'Name Length', 'ratio': 'Ratio Between Covid Words to Total Name Length'})\n",
    "\n",
    "    desc_df = count_words_in_df(df_2020_lst, COVID_WORDS, 'description')[['counts','total','ratio','price']]\n",
    "    desc_df['price'] = desc_df['price'].apply(fix_price)\n",
    "    desc_df = desc_df.corr().loc[['counts','total', 'ratio'], 'price']\n",
    "    desc_df = desc_df.rename({\"counts\": 'Covid Words Used in Description', 'total': 'Description Length', 'ratio': 'Ratio Between Covid Words to Description Length'})\n",
    "\n",
    "    final_df = pd.DataFrame(pd.concat((name_df, desc_df)))\n",
    "    fig = go.Figure(data=go.Table(header=dict(values = ['','price'],\n",
    "                                              fill_color='paleturquoise',\n",
    "                                              font_size=20\n",
    "                                              ),\n",
    "                                  cells=dict(\n",
    "                                      values=[[x for x in final_df.index],[f'{x[0]:.3f}' for x in final_df.values]],\n",
    "                                      fill_color='lavender'\n",
    "                                  )),\n",
    "                    layout=dict(title='Pearson Correlation Between Covid Words Occurrences in Names & Descriptions to Listing Price'))\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:04:07.832260Z",
     "start_time": "2022-02-27T18:01:54.804668Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_covid_words_price_names_desc().show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**There seems to be no correlation between the amount of Covid words in a name or description of a listing to its price during covid**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews\n",
    "\n",
    "Exploring reviews data and differences due to Covid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Words in Reviews Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:04:07.848264Z",
     "start_time": "2022-02-27T18:04:07.833262Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_reviews_word_cloud(df, title, min_count = 2500):\n",
    "    names = df[\"comments\"].tolist()\n",
    "    plt.figure(figsize = (15, 15), facecolor = None)\n",
    "    plt.title(title)\n",
    "    plt.imshow(create_word_cloud(names, min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:04:21.425125Z",
     "start_time": "2022-02-27T18:04:07.850264Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_reviews_word_cloud(df_pre_reviews, \"Pre-covid Reviews Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:04:33.044456Z",
     "start_time": "2022-02-27T18:04:21.426126Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_reviews_word_cloud(df_covid_reviews, \"Covid Reviews Word Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New Words Used in Review During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:04:51.034505Z",
     "start_time": "2022-02-27T18:04:33.045457Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_words_after_covid([df_pre_reviews['comments'].tolist()],\n",
    "                      [df_covid_reviews['comments'].tolist()],\n",
    "                      \"Top New Words in Reviews During Covid\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Word Occurrences Changes Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:05:14.548466Z",
     "start_time": "2022-02-27T18:04:51.035506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "words_change([df_pre_reviews[\"comments\"].tolist()], [df_covid_reviews[\"comments\"].tolist()],\n",
    "             \"Top Words Occurrences Difference Pre-covid than During Covid in Reviews\",\n",
    "             [\"Words Occurrences Difference Higher Pre-Covid \", \"Words Occurences Difference Lower During Covid\"]).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Just like in the names and descriptions we can see that most of the new words used are Covid related words (Covid, pandemic, quarantine, WFH and more).**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sentiment Change in Reviews Pre & During Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:07:24.623441Z",
     "start_time": "2022-02-27T18:05:31.671091Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analysis_diff([df_pre_reviews[\"comments\"].tolist()], [df_covid_reviews[\"comments\"].tolist()],\n",
    "                        \"Sentiment Analysis for Pre and During Covid Reviews\").show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Interestingly we can see that both subjectivity and polarity values have increased a bit during Covid. Meaning the reviews are more subjective and more positive.**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Correlation Between Review to Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Correlation Between Covid Words in Reviews to Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:09:39.395258Z",
     "start_time": "2022-02-27T18:09:39.387257Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def corr_covid_words_review(df_lst, df_review):\n",
    "    df = pd.merge(df_lst, df_review, left_on='id', right_on='listing_id')[['comments','review_scores_rating']]\n",
    "    counts_df = count_words_in_df(df, COVID_WORDS, 'comments')[['counts','total','ratio','review_scores_rating']]\n",
    "    counts_df = pd.DataFrame(counts_df.corr().loc[['counts', 'total', 'ratio'], 'review_scores_rating'])\n",
    "    counts_df = counts_df.rename({\"counts\": 'Covid Words Used in Comment', 'total': 'Comment Length', 'ratio': 'Ratio Between Covid Words to Comment Length',\n",
    "                                  'review_scores_rating': 'Rating'})\n",
    "    fig = go.Figure(data=go.Table(header=dict(values = ['','Rating'],\n",
    "                                                  fill_color='paleturquoise',\n",
    "                                                  font_size=20\n",
    "                                                  ),\n",
    "                                      cells=dict(\n",
    "                                          values=[[x for x in counts_df.index],[f'{x[0]:.3f}' for x in counts_df.values]],\n",
    "                                          fill_color='lavender'\n",
    "                                      )),\n",
    "                        layout=dict(title=\"Pearson Correlation Between Covid Words Occurrences in Reviews to Listing's Rating\"))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:10:47.850924Z",
     "start_time": "2022-02-27T18:09:39.396260Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr_covid_words_review(df_2020_lst,df_covid_reviews).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**As is with names and descriptions there is no correlation betweeen the amount of Covid words in a review to a listings ratings**\n",
    "<br><br><br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Correlation between Review Sentiment to Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:10:47.866936Z",
     "start_time": "2022-02-27T18:10:47.851926Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def corr_sentiment_review_rating(df_lst, df_review, title):\n",
    "    def convert_sentiment_to_cat(pol):\n",
    "        if pol < -0.33:\n",
    "            return -1\n",
    "        elif pol < 0.33:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    df = pd.merge(df_lst, df_review, left_on='id', right_on='listing_id')[['id_x', 'comments', 'review_scores_rating']]\n",
    "    sentiments_lst = get_sentiment_analysis([df.loc[:,'comments'].tolist()])\n",
    "    df['Polarity'] = sentiments_lst['polarity']\n",
    "    df['Subjectivity'] = sentiments_lst['subjectivity']\n",
    "    sentiment_df = df.groupby('id_x').mean().reset_index()\n",
    "    sentiment_df = sentiment_df.drop('id_x', axis=1)\n",
    "    sentiment_df['Polarity'] = sentiment_df['Polarity'].apply(convert_sentiment_to_cat)\n",
    "    sentiment_df['Subjectivity'] = sentiment_df['Subjectivity'].apply(convert_sentiment_to_cat)\n",
    "\n",
    "    sentiment_df = sentiment_df.corr().loc[['Polarity', 'Subjectivity'], 'review_scores_rating']\n",
    "    fig = go.Figure(data=go.Table(header=dict(values = ['','Rating'],\n",
    "                                              fill_color='paleturquoise',\n",
    "                                              font_size=20\n",
    "                                              ),\n",
    "                                  cells=dict(\n",
    "                                      values=[[x for x in sentiment_df.index],[f'{x:.3f}' for x in sentiment_df.values]],\n",
    "                                      fill_color='lavender'\n",
    "                                  )),\n",
    "                    layout=dict(title=title))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:11:29.712537Z",
     "start_time": "2022-02-27T18:10:47.868442Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_sentiment_review_rating(df_pre,df_pre_reviews,\n",
    "                             'Pearson Correlation Between Mean Polarity & Subjectivity of Reviews to Listing Rating Before Covid').show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:12:04.572702Z",
     "start_time": "2022-02-27T18:11:29.714537Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_sentiment_review_rating(df_2020_lst, df_covid_reviews,\n",
    "                             'Pearson Correlation Between Mean Polarity & Subjectivity of Reviews to Listing Rating at Beginning of Covid').show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:12:53.957727Z",
     "start_time": "2022-02-27T18:12:04.573702Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_sentiment_review_rating(df_21_sep_lst, df_covid_reviews,\n",
    "                             'Pearson Correlation Between Mean Polarity & Subjectivity of Reviews to Listing Rating During Covid').show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**There is very little correlation between the mean polarity & subjectivity of reviews to a listing's rating before and during Covid (both at the begining and in a later period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reviews Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:12:55.502592Z",
     "start_time": "2022-02-27T18:12:53.959728Z"
    },
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_box_compare(data, names):\n",
    "    fig = go.Figure()\n",
    "    for curr, name in zip(data, names):\n",
    "        fig.add_trace(go.Box(x=data, name=name))\n",
    "    return fig\n",
    "\n",
    "draw_box_compare([df_pre['review_scores_rating'].tolist(),df_2020_lst['review_scores_rating'].tolist(), df_21_sep_lst['review_scores_rating'].tolist()],\n",
    "                 ['Pre-covid','Start of Covid (June 2020)', 'During Covid (Septmeber 2021)']).show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Although the amount of reviews have changed drastically during these 3 periods the listing score distributions stayed the same. Showing that people scoring didn't change due to Covid, although we can see that their reviews text did and their subjectivity and polarity changed due to Covid.**\n",
    "<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Find Patterns Using Word Embeddings on Reviews\n",
    "\n",
    "Here I will try to see if I can find any interesting patterns in reviews using word embeddings. I will use Word2Vec model for creationg embeddings from scratch from all the reviews data during Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:02:09.508057Z",
     "start_time": "2022-02-27T20:02:09.484052Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_a_clean_corpus(corpus):\n",
    "    tokenized_corpus = list()\n",
    "    for sentence in corpus:\n",
    "        clean_tokens = list()\n",
    "        for word in sentence.split(\" \"):\n",
    "            if re.match(r\"[^\\w\\s]|[(\\d)+]$\",word) is not None or exclude_word(word):\n",
    "                continue\n",
    "            new_word = strip_punc_digit(word)\n",
    "            if len(new_word) > 0:\n",
    "                clean_tokens.append(new_word.lower())\n",
    "        if len(clean_tokens) != 0:\n",
    "            tokenized_corpus.append(clean_tokens)\n",
    "\n",
    "    return tokenized_corpus\n",
    "\n",
    "\n",
    "def train_word2vec_model(data: List[List[str]], embedding_size=100, window_size=7, min_word_count=5):\n",
    "    corpus = clean_and_flatten_corpus(data)\n",
    "    tokenized_corpus = tokenize_a_clean_corpus(corpus)\n",
    "    model = Word2Vec(sentences=tokenized_corpus, vector_size=embedding_size, window=window_size, min_count=min_word_count, workers=4)\n",
    "    return model\n",
    "\n",
    "def get_similarity_word_cloud(source_words: List[str], model, num_words):\n",
    "    similarity_factor = 100\n",
    "    most_similar_words = list()\n",
    "    for word in source_words:\n",
    "        try:\n",
    "            similar_words = model.wv.most_similar(word, topn=num_words)\n",
    "            most_similar_words.append((word, similarity_factor*2))\n",
    "            most_similar_words += [(curr[0], int(curr[1]*similarity_factor)) for curr in similar_words]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    most_similar_words = sorted(most_similar_words, key=lambda t: t[1])\n",
    "    freq_quantile = [most_similar_words[len(most_similar_words)//3][1], most_similar_words[(len(most_similar_words)*2)//3][1]]\n",
    "    words_dict = {word: val for word, val in most_similar_words}\n",
    "\n",
    "    def coloring_func(word, *args, **kwargs):\n",
    "        colors = [(17,225,0),(200,255,104), (255,255,104), (255,247,10)]\n",
    "        freq = words_dict.get(word.lower(),0)\n",
    "        idx=3\n",
    "        if freq > freq_quantile[0]:\n",
    "            idx = 1\n",
    "        elif freq > freq_quantile[1]:\n",
    "            idx = 2\n",
    "        return  colors[0] if word.lower() in source_words else colors[idx]\n",
    "\n",
    "    return create_word_cloud(words_dict, min_count=0, color_func=coloring_func)\n",
    "\n",
    "\n",
    "def get_most_similar_words(words: List[str], model, num_words: int=10):\n",
    "    most_similar_words = list()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = model.wv.most_similar(word, topn=num_words)\n",
    "            most_similar_words += [x[0] for x in similar_words]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return most_similar_words + words\n",
    "\n",
    "\n",
    "def create_tsne_fig_of_words(words: List[str], model, title, color_values=None, perplexity=40, r_state=None):\n",
    "\n",
    "    embeddings = list()\n",
    "    used_words = list()\n",
    "    for word in words:\n",
    "        try:\n",
    "            embeddings.append(model.wv[word])\n",
    "            used_words.append(word)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    new_embeddings = TSNE(init='pca', perplexity=perplexity, n_iter=3000, random_state=r_state).fit_transform(embeddings)\n",
    "    df = pd.DataFrame({\"word\": used_words,\n",
    "                       \"tsne1\": [embed[0] for embed in new_embeddings],\n",
    "                       \"tsne2\": [embed[1] for embed in new_embeddings]})\n",
    "    color_map = None\n",
    "    if color_values is not None:\n",
    "        df['Type'] = df['word'].apply(color_values)\n",
    "        color_map = {color: color for color in df['Type']}\n",
    "\n",
    "    fig = px.scatter(df, x='tsne1', y='tsne2', text='word',\n",
    "                     color='Type' if color_values is not None else None,\n",
    "                     color_discrete_map=color_map, title=title)\n",
    "    fig.update_traces(textposition='top center')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def paint_similarity_word_cloud(source_words: List[str], model, title, num_words=50):\n",
    "    wordcloud = get_similarity_word_cloud(source_words, model, num_words)\n",
    "    plt.figure(figsize = (10, 10), facecolor = None)\n",
    "    plt.title(title)\n",
    "    plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:13:54.706592Z",
     "start_time": "2022-02-27T20:02:12.141286Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "covid_embeddings_model = train_word2vec_model([df_covid_reviews[\"comments\"].tolist()], min_word_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Covid Related Words by Embedding Similarity Word Cloud\n",
    "\n",
    "Here there is a word cloud of Covid Words fand their most similar words according to the Word2Vec model.\n",
    "The colors of the words are according to similarity distance Green - most similar, yellow - least similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:13:55.726358Z",
     "start_time": "2022-02-27T20:13:54.723596Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paint_similarity_word_cloud(COVID_WORDS, covid_embeddings_model, 'Similar Words to Covid Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Words Similarity\n",
    "\n",
    "Here I use T-SNE to decrease the embeddings dimension and display them in a 2D map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:24:37.590914Z",
     "start_time": "2022-02-27T18:24:37.081778Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_tsne_fig_of_words(COVID_WORDS, covid_embeddings_model, 'Covid Words Similarity',perplexity=8, r_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the graph above we see that model learned some logical patterns about the Covid words:\n",
    "* Words related to sanitation are clustered together (bottom right).\n",
    "* Words related to healthcare and regulations are clustered near one another.\n",
    "* All the Covid words are clustered near one another together with the word virus in between (top left).\n",
    "<br><br>\n",
    "---\n",
    "<br>Below is a graph displaying the similarity of some of the Covid words (I didn't used all to make this graph more readable) and other words from reviews. The words used are separated to 2 groups to words that have a good meaning in a review and words that have a bad meaning in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:24:37.974000Z",
     "start_time": "2022-02-27T18:24:37.591914Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_words = {'good', 'comfortable', 'nice', 'comfy', 'beautiful', 'amazing', 'awesome', 'great', 'excellent', 'amazing', 'stunning', 'lovely',\n",
    "              'fantastic', 'perfect', 'incredible', 'fabulous', 'cool', 'wonderful', 'phenomenal', 'spectacular'}\n",
    "bad_words = {'bad', 'uncomfortable', 'ugly', 'annoying', 'stink', 'stinks', 'unpleasant', 'annoying', 'suck', 'awful', 'disappointing', 'negative', 'mean',\n",
    "             'frustrating', 'disappointed', 'dangerous', 'gross', 'inconvenient', 'messy', 'unsanitary', 'dirty', 'filthy'}\n",
    "covid_words_tsne = {'covid', 'quarantine', 'pandemic', 'corona', 'disinfection', 'bacterial', 'germ', 'virus', 'sanitize', 'vaccine', 'pandemic', 'bacteria',\n",
    "                    'isolation', 'disinfect', 'anti_bacterial'}\n",
    "\n",
    "def coloring_func(word):\n",
    "    if word in good_words:\n",
    "        return 'green'\n",
    "    if word in bad_words:\n",
    "        return 'red'\n",
    "    return 'yellow'\n",
    "\n",
    "legend_dict = {'green': 'Good Words', 'red': 'Bad Words', 'yellow': 'Covid Words'}\n",
    "\n",
    "to_use = covid_words_tsne.union(good_words).union(bad_words)\n",
    "tsne_fig = create_tsne_fig_of_words(to_use, covid_embeddings_model, 'Covid and General Words Similarity', color_values=coloring_func, r_state=92)\n",
    "tsne_fig.for_each_trace(lambda trace: trace.update(name=legend_dict[trace.name],\n",
    "                                                   legendgroup = legend_dict[trace.name],\n",
    "                                                   hovertemplate = trace.hovertemplate.replace(trace.name, legend_dict[trace.name])))\n",
    "\n",
    "\n",
    "tsne_fig.show(renderer=RENDERER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "**In this grpah we can see that the good words are clustered together at the top left corner and most of the Covid words are clustered one near the other but are interlaced with other bad words. Showing that from the reviews the model learned that covid words are mostly words that have a bad meaning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Clustering on Reviews\n",
    "\n",
    "Exploring to see if using Latent Dirichlet Allocation can cluster the comments, in different ways.\n",
    "<br>\n",
    "In this part I used only 30,000 reviews from ~500,000 due to memory limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:49:12.513745Z",
     "start_time": "2022-02-27T18:49:12.503240Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_counts_df(corpus: List[str], ngram_range=(1, 1)):\n",
    "    stop_words = set(nltk_stopwords.words(\"english\")).union(nltk_stopwords.words(\"spanish\")).union(nltk_stopwords.words(\"french\"))\n",
    "    cv = CountVectorizer(analyzer=\"word\", stop_words=stop_words, ngram_range=ngram_range, lowercase=True)\n",
    "    term_matrix = cv.fit_transform(corpus)\n",
    "    counts_df = pd.DataFrame(term_matrix.toarray(), columns=cv.get_feature_names_out())\n",
    "    return counts_df\n",
    "\n",
    "\n",
    "def create_and_train_lda_model(counts_df: pd.DataFrame, num_of_topics):\n",
    "    df = counts_df.apply(lambda word_count: word_count > 0)\n",
    "    sentences_clean = df.apply(lambda row: list(counts_df.columns[row.values]), axis=1)\n",
    "    dictionary = gensim.corpora.Dictionary(sentences_clean)\n",
    "    topic_modeling = [dictionary.doc2bow(text) for text in sentences_clean]\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=topic_modeling, id2word=dictionary, num_topics=num_of_topics, random_state=100, update_every=0,\n",
    "                                                chunksize=30, passes=10, alpha='symmetric', iterations=100, per_word_topics=True)\n",
    "\n",
    "    return lda_model, topic_modeling\n",
    "\n",
    "\n",
    "def create_lda_vis(data: List[List[str]], num_of_topics, ngram_range=(1, 1)):\n",
    "    corpus = clean_and_flatten_corpus(data)\n",
    "    counts_df = create_counts_df(corpus, ngram_range)\n",
    "    lda_model, topic_modeling = create_and_train_lda_model(counts_df, num_of_topics)\n",
    "    vis = gensimvis.prepare(lda_model, topic_modeling, dictionary=lda_model.id2word)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Reviews by Ratings (1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:52:41.267809Z",
     "start_time": "2022-02-27T18:49:35.190047Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_lda_vis([df_pre_reviews[\"comments\"].tolist()[:10_000], df_covid_reviews[\"comments\"].tolist()[:10_000]], num_of_topics=5, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method failed, clustering for rating doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Reviews by Pre & Post Covid comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T18:56:17.715388Z",
     "start_time": "2022-02-27T18:52:43.110484Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_lda_vis([df_pre_reviews[\"comments\"].tolist()[:10_000], df_covid_reviews[\"comments\"].tolist()[:10_000]], num_of_topics=2, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This clustering did split the comments into 2 distinct clusters but none of the Covid words appear as the top words, and their sizes is significanlty differnt, meaning it didn't split well between based on different periods.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}